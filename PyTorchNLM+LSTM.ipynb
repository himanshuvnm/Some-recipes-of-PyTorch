{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdVdAd0x9UrU",
        "outputId": "c64f45e1-04cd-4d92-aba3-9e416af19817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7816b072d9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# create a word-embedding model using PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix={\"data\":0,\"science\":1}\n",
        "word_to_ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwaoI3Yh-BpF",
        "outputId": "693770d8-a13d-4b46-b670-8736b5ef0698"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 0, 'science': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeds=nn.Embedding(2,5)#2 words in vocab, 5 dimensional embeddings"
      ],
      "metadata": {
        "id": "lag0uepz-Vee"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_tensor=torch.tensor([word_to_ix[\"data\"]],dtype=torch.long)"
      ],
      "metadata": {
        "id": "llOi2sNPJPxG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4nov6HyJl-V",
        "outputId": "ce3f7f16-45f8-4ff7-a48e-d82b8f582d4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we set up an embedding layer"
      ],
      "metadata": {
        "id": "wKh6MyjlJr2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hello_embed=embeds(lookup_tensor)"
      ],
      "metadata": {
        "id": "ZZ-ESxtNJoGa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hello_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7prS5mJ2rl",
        "outputId": "d1a923a1-2027-4719-cfae-4b8308f7fdb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1021, -0.2590, -0.1549, -1.3706, -0.1319]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE=2\n",
        "EMBEDDING_DIM=10"
      ],
      "metadata": {
        "id": "xIq1x25IJ5Ez"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following test sentence is the wiki article of PyTorch available at https://en.wikipedia.org/wiki/PyTorch"
      ],
      "metadata": {
        "id": "621DFmozK3GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence=\"\"\"PyTorch is a machine learning library based on the Torch library,[4][5][6] used for applications such as computer vision and natural language processing,[7] originally developed by Meta AI and now part of the Linux Foundation umbrella.[8][9][10][11] It is recognized as one of the two most popular machine learning libraries alongside TensorFlow, offering free and open-source software released under the modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.[12]\"\"\".split()"
      ],
      "metadata": {
        "id": "hVCtTRTNJ985"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introducing tokenization of the words to split sentences into small chunks."
      ],
      "metadata": {
        "id": "2kQwYFsKKlsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigrams=[(test_sentence[i], test_sentence[i+1], test_sentence[i+2]) for i in range(len(test_sentence)-2)]"
      ],
      "metadata": {
        "id": "SlN-qak9KhyK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trigrams[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnvnTnsHLYAE",
        "outputId": "02c255ae-18ae-4020-acdc-470fe7e0c3f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('PyTorch', 'is', 'a'), ('is', 'a', 'machine'), ('a', 'machine', 'learning')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=set(test_sentence)"
      ],
      "metadata": {
        "id": "ixK6D7iULfuT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix={word: i for i, word in enumerate(vocab)}\n",
        "word_to_ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y44VrosLLnBM",
        "outputId": "aa257058-8753-47ee-a465-c29951ba771f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'originally': 0,\n",
              " 'and': 1,\n",
              " 'umbrella.[8][9][10][11]': 2,\n",
              " 'BSD': 3,\n",
              " 'libraries': 4,\n",
              " 'license.': 5,\n",
              " 'interface': 6,\n",
              " 'free': 7,\n",
              " 'natural': 8,\n",
              " 'polished': 9,\n",
              " 'by': 10,\n",
              " 'has': 11,\n",
              " 'learning': 12,\n",
              " 'processing,[7]': 13,\n",
              " 'machine': 14,\n",
              " 'now': 15,\n",
              " 'It': 16,\n",
              " 'popular': 17,\n",
              " 'Torch': 18,\n",
              " 'development,': 19,\n",
              " 'under': 20,\n",
              " 'Although': 21,\n",
              " 'such': 22,\n",
              " 'used': 23,\n",
              " 'open-source': 24,\n",
              " 'applications': 25,\n",
              " 'software': 26,\n",
              " 'based': 27,\n",
              " 'more': 28,\n",
              " 'a': 29,\n",
              " 'for': 30,\n",
              " 'the': 31,\n",
              " 'alongside': 32,\n",
              " 'offering': 33,\n",
              " 'developed': 34,\n",
              " 'TensorFlow,': 35,\n",
              " 'library,[4][5][6]': 36,\n",
              " 'AI': 37,\n",
              " 'Foundation': 38,\n",
              " 'most': 39,\n",
              " 'released': 40,\n",
              " 'vision': 41,\n",
              " 'one': 42,\n",
              " 'language': 43,\n",
              " 'primary': 44,\n",
              " 'focus': 45,\n",
              " 'computer': 46,\n",
              " 'C++': 47,\n",
              " 'library': 48,\n",
              " 'Meta': 49,\n",
              " 'modified': 50,\n",
              " 'Python': 51,\n",
              " 'as': 52,\n",
              " 'two': 53,\n",
              " 'recognized': 54,\n",
              " 'also': 55,\n",
              " 'on': 56,\n",
              " 'interface.[12]': 57,\n",
              " 'of': 58,\n",
              " 'Linux': 59,\n",
              " 'part': 60,\n",
              " 'is': 61,\n",
              " 'PyTorch': 62}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting key-word via PyTorch n-grams."
      ],
      "metadata": {
        "id": "pzlrbnupL7ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramLanguageModeler(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim,context_size):\n",
        "    super(NGramLanguageModeler,self).__init__()\n",
        "    self.embeddings=nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.linear1=nn.Linear(context_size*embedding_dim,128)\n",
        "    self.linear2=nn.Linear(128,vocab_size)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    embeds=self.embeddings(input).view((1,-1))\n",
        "    out=F.relu(self.linear1(embeds))\n",
        "    out=self.linear2(out)\n",
        "    log_probs=F.log_softmax(out,dim=1)\n",
        "    return log_probs\n",
        "\n",
        "losses=[]\n",
        "loss_function=nn.NLLLoss()\n",
        "model=NGramLanguageModeler(len(vocab),EMBEDDING_DIM,CONTEXT_SIZE)\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "jh1FR0LqLxyD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNIp-mwZNEKa",
        "outputId": "6640ff4e-a53e-481d-b30d-5ea13bf1906b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYbCxj8KP2e2",
        "outputId": "81fd4a4a-c9b0-4e17-d813-f49a835ed39d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NLLLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeikfpGkP45Z",
        "outputId": "c2781046-db4e-41af-ca18-4c090688342e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NGramLanguageModeler(\n",
              "  (embeddings): Embedding(63, 10)\n",
              "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=63, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0YnvttYQQml",
        "outputId": "1643bb63-7287-4f49-e3de-d0923582267e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Context extraction from sentences\n",
        "for epoch in range(10):\n",
        "  total_loss=0\n",
        "  for context, target in zip(trigrams,trigrams):\n",
        "    #Step 1: Pass the inputs into model(words into numbers then wrap into tensores)\n",
        "    context_idxs=torch.tensor([word_to_ix[w] for w in context],dtype=torch.long)\n",
        "    #Step 2: Zero-ing out the gradients a torch accumulats gradients\n",
        "    model.zero_grad()\n",
        "    #Step 3: Forward pass, log-probabilities over the next word\n",
        "    log_probs=model(context_idxs)\n",
        "    #Step 4: Compute the loss function.\n",
        "    loss=loss_function(log_probs, torch.tensor([word_to_ix[target]],dtype=torch.long))\n",
        "    #Step 5: Backward pass and update the gradient\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss+=loss.item()\n",
        "  loss.append(total_loss)\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "aPrRWiunQTzL",
        "outputId": "cff6da01-24e1-46b6-d1e7-d33ee89b869e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not method",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-73b84fa0d4d1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Step 3: Forward pass, log-probabilities over the next word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlog_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Step 4: Compute the loss function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-983c5fc6797f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0membeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2235\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not method"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#continuous bag of words (CBOW) and skip gram\n",
        "CONTEXT_SIZE=2;\n",
        "raw_text=\"\"\"PyTorch is a machine learning library based on the Torch library,[4][5][6] used for applications such as computer vision and natural language processing,[7] originally developed by Meta AI and now part of the Linux Foundation umbrella.[8][9][10][11] It is recognized as one of the two most popular machine learning libraries alongside TensorFlow, offering free and open-source software released under the modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.[12]\n",
        "\n",
        "A number of pieces of deep learning software are built on top of PyTorch, including Tesla Autopilot,[13] Uber's Pyro,[14] Hugging Face's Transformers,[15] PyTorch Lightning,[16][17] and Catalyst.[18][19]\"\"\".split()"
      ],
      "metadata": {
        "id": "WGMFFKecS7is"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#de-duplicate the array\n",
        "vocab=set(raw_text)\n",
        "vocab_size=len(vocab)\n",
        "\n",
        "word_to_ix={word: i for i, word in enumerate(vocab)}\n",
        "data=[]\n",
        "for i in range(2, len(raw_text)-2):\n",
        "  context=[raw_text[i-2],raw_text[i-1],raw_text[i+1],raw_text[i+2]]\n",
        "  target=raw_text[i]\n",
        "  data.append((context,target))\n",
        "print(data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro71YWj6brKp",
        "outputId": "f1fd43e7-18e8-47cf-be36-4a49aeb144a7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['PyTorch', 'is', 'machine', 'learning'], 'a'), (['is', 'a', 'learning', 'library'], 'machine'), (['a', 'machine', 'library', 'based'], 'learning'), (['machine', 'learning', 'based', 'on'], 'library'), (['learning', 'library', 'on', 'the'], 'based')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "      pass\n",
        "      def forward(self,inputs):\n",
        "        pass\n",
        "\n",
        "def  make_context_vector(context, word_to_ix):\n",
        "  idxs=[word_to_ix[w] for w in context]\n",
        "  return torch.tensor(idxs,dtype=torch.long)\n",
        "\n",
        "make_context_vector(data[0][0], word_to_ix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfhsnMzScrRO",
        "outputId": "47e04a83-28d4-4d80-cd1e-d5f01f757f38"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([19, 42, 47,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin=nn.Linear(5,3)\n",
        "data=torch.randn(2,5)\n",
        "print(lin(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOyfLyuidsy5",
        "outputId": "59982b61-d2e6-4e78-832d-38875dda5c7a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6651,  0.0700, -0.2061],\n",
            "        [ 0.2934,  0.5486, -0.4480]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.randn(2,2)\n",
        "print(data)\n",
        "print(F.relu(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z3r4RASeBK3",
        "outputId": "56b72628-6eca-45bc-af4d-4afcee6a3da0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.4497, -0.0026],\n",
            "        [-1.7472, -0.6526]])\n",
            "tensor([[1.4497, 0.0000],\n",
            "        [0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.randn(5)\n",
        "print(data)\n",
        "print(F.softmax(data,dim=0))\n",
        "print(F.softmax(data,dim=0).sum())\n",
        "print(F.log_softmax(data,dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwIPnxueeKp6",
        "outputId": "e5daa3e3-849a-4920-df63-eeb5e2379164"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3233,  0.8929, -0.5331, -0.2413, -0.9804])\n",
            "tensor([0.2480, 0.4383, 0.1053, 0.1410, 0.0673])\n",
            "tensor(1.0000)\n",
            "tensor([-1.3944, -0.8247, -2.2507, -1.9590, -2.6980])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we shall prepare a specific form of recurrent neural network, called as Long-Short Term Memory Model (LSTMM)."
      ],
      "metadata": {
        "id": "CQ_GhT_wgg-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm=nn.LSTM(3,3)\n",
        "inputs=[torch.randn(1,3) for _ in range(5)]\n",
        "hidden=(torch.randn(1,1,3),\n",
        "        torch.randn(1,1,3))\n",
        "\n",
        "for i in inputs:\n",
        "  out, hidden=lstm(i.view(1,1,-1),hidden)\n",
        "\n",
        "inputs=torch.cat(inputs).view(len(inputs),1,-1)\n",
        "hidden=(torch.randn(1,1,3),torch.randn(1,1,3))\n",
        "out,hidden=lstm(inputs,hidden)\n",
        "print(out)\n",
        "print(hidden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfo31NlwelUc",
        "outputId": "9eab66f9-cd84-4125-bcba-58272f9abcac"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0124, -0.0072,  0.3236]],\n",
            "\n",
            "        [[-0.1823,  0.2966,  0.2160]],\n",
            "\n",
            "        [[-0.2137,  0.2821,  0.2430]],\n",
            "\n",
            "        [[-0.2842,  0.4189,  0.1871]],\n",
            "\n",
            "        [[-0.1355,  0.1876,  0.0799]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
            "(tensor([[[-0.1355,  0.1876,  0.0799]]], grad_fn=<StackBackward0>), tensor([[[-0.3803,  0.6267,  0.1372]]], grad_fn=<StackBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare a sequence of words as training data to form the LSTM network\n",
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs=[to_ix[w] for w in seq]\n",
        "  return torch.tensor(idxs,dtype=torch.long)\n",
        "\n",
        "training_data=[(\"Probability and random variables are integral part of computation\".split(),[\"DET\",\"NN\",\"V\",\"DET\",\"NN\"]),\n",
        "    (\"I am learning LLM,LAM,G-AI\".split(),[\"NN\",\"V\",\"DET\",\"NN\"])\n",
        "               ]"
      ],
      "metadata": {
        "id": "YkHyRX6fiJcP"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ7J_EEujd9G",
        "outputId": "531752d4-6dd5-4c64-c8a9-c9b5ef6ffaa9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Probability',\n",
              "   'and',\n",
              "   'random',\n",
              "   'variables',\n",
              "   'are',\n",
              "   'integral',\n",
              "   'part',\n",
              "   'of',\n",
              "   'computation'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN']),\n",
              " (['I', 'am', 'learning', 'LLM,LAM,G-AI'], ['NN', 'V', 'DET', 'NN'])]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_t_ix={}\n",
        "for sent, tags in training_data:\n",
        "  for word in sent:\n",
        "    if word not in word_to_ix:\n",
        "      word_to_ix[word]=len(word_t_ix)\n",
        "print(word_to_ix)\n",
        "tag_to_ix={\"DET\":0,\"V\":1,\"NN\":2}\n",
        "\n",
        "EMBEDDING_DIM=6\n",
        "HIDDEEN_DIM=6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMcN-w6wjnLA",
        "outputId": "0e2bd8f6-0fb0-4c6b-e3b7-4bd95f46f2d0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pyro,[14]': 0, 'BSD': 1, 'natural': 2, 'by': 3, 'learning': 4, 'now': 5, 'development,': 6, 'based': 7, 'developed': 8, 'AI': 9, 'Foundation': 10, 'one': 11, 'pieces': 12, 'language': 13, 'are': 14, 'C++': 15, 'A': 16, 'as': 17, 'Linux': 18, 'PyTorch': 19, 'Lightning,[16][17]': 20, 'Autopilot,[13]': 21, 'free': 22, 'top': 23, 'polished': 24, 'Transformers,[15]': 25, 'processing,[7]': 26, 'It': 27, 'Torch': 28, 'under': 29, 'for': 30, 'the': 31, 'Hugging': 32, 'vision': 33, 'primary': 34, 'modified': 35, 'Meta': 36, \"Face's\": 37, 'two': 38, 'also': 39, 'on': 40, 'part': 41, 'is': 42, 'originally': 43, 'umbrella.[8][9][10][11]': 44, 'interface': 45, 'has': 46, 'machine': 47, 'popular': 48, 'such': 49, 'used': 50, 'open-source': 51, 'applications': 52, 'more': 53, 'Tesla': 54, 'offering': 55, 'TensorFlow,': 56, 'library': 57, 'Python': 58, 'PyTorch,': 59, 'interface.[12]': 60, 'of': 61, 'and': 62, 'Catalyst.[18][19]': 63, 'libraries': 64, 'license.': 65, 'Although': 66, 'software': 67, 'a': 68, 'alongside': 69, 'library,[4][5][6]': 70, 'most': 71, 'released': 72, 'deep': 73, \"Uber's\": 74, 'focus': 75, 'computer': 76, 'including': 77, 'recognized': 78, 'number': 79, 'built': 80, 'Probability': 0, 'random': 0, 'variables': 0, 'integral': 0, 'computation': 0, 'I': 0, 'am': 0, 'LLM,LAM,G-AI': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "  def __init__(self,embedding_dim,hidden_dim,vocab_size,target_size):\n",
        "      super(LSTMTagger,self).__init__()\n",
        "      self.hidden_dim=hidden_dim\n",
        "\n",
        "      self.word_embeddings=nn.Embedding(vocab_size,embedding_dim)\n",
        "      self.lstm=nn.LSTM(embedding_dim,hidden_dim)\n",
        "\n",
        "      self.hidden2tag=nn.Linear(hidden_dim,target_size)\n",
        "      self.hidden=self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return (torch.zeros(1,1,self.hidden_dim),\n",
        "            torch.zeros(1,1,self.hidden_dim))\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embdes=self.word_embeddings(sentence)\n",
        "    lstm_out, self.hidden=self.lstm(\n",
        "        embdes.view(len(sentence),1,-1),self.hidden)\n",
        "    tag_space=self.hidden2tag(lstm_out.view(len(sentence),-1))\n",
        "    tag_scores=F.log_softmax(tag_space,dim=1)\n",
        "    return tag_scores"
      ],
      "metadata": {
        "id": "JV-8F5zokTy0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=LSTMTagger(EMBEDDING_DIM,HIDDEEN_DIM,len(word_to_ix),len(tag_to_ix))\n",
        "loss_function=nn.NLLLoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=.1)\n",
        "model\n",
        "loss_function\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5StXoBhnIhU",
        "outputId": "ee0d44ca-3276-4da8-84ae-033eeed7ba2d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.1\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  inputs=prepare_sequence(training_data[0][0],word_to_ix)\n",
        "  tag_scores=model(inputs)\n",
        "  print(tag_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vom5wYEPnxui",
        "outputId": "f05f1ee3-647c-4c3d-c8ab-7e374d4ea32f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0243, -1.2688, -1.0222],\n",
            "        [-1.0162, -1.2989, -1.0073],\n",
            "        [-1.0630, -1.2351, -1.0113],\n",
            "        [-1.0429, -1.2376, -1.0287],\n",
            "        [-0.9808, -1.3155, -1.0310],\n",
            "        [-1.0002, -1.2729, -1.0436],\n",
            "        [-0.9511, -1.3455, -1.0405],\n",
            "        [-0.9889, -1.3068, -1.0291],\n",
            "        [-1.0214, -1.2596, -1.0325]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "  for sentence, tags in training_data:\n",
        "    model.zero_grad()\n",
        "    model.hidden=model.init_hidden()\n",
        "    sentence_in=prepare_sequence(sentence,word_to_ix)\n",
        "    targets=prepare_sequence(tags,tag_to_ix)\n",
        "    tag_scores=model(sentence_in)\n",
        "    loss=loss_function(tag_scores, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "mrrpjecbpLN9",
        "outputId": "196f85dc-0bf3-4174-e386-2ab447884080"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (9) to match target batch_size (5).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-74dd93a4cdba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepare_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtag_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2733\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (9) to match target batch_size (5)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iGVTKxUqWCo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}